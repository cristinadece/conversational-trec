{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f14b944a-6704-4583-8437-688a470389d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter, defaultdict\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adb41179-1233-4dc2-a36d-30f1197b179f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.7.1 has loaded Terrier 5.6 (built by craigmacdonald on 2021-09-17 13:27)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "import pyterrier as pt\n",
    "pt.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ba4f445-0238-435c-9c6f-33bdb98a8758",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jnius import autoclass\n",
    "tokeniser = autoclass(\"org.terrier.indexing.tokenisation.Tokeniser\").getTokeniser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "086c7150-11aa-46ee-9353-026600c339a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def terrier_tokenizer(raw_utterance):\n",
    "    new_utterance = \" \".join(tokeniser.getTokens(raw_utterance))\n",
    "    return new_utterance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c942ad3f-ab0b-4b2e-9b2d-f412a3d61c79",
   "metadata": {},
   "source": [
    "# Retrieve docs per MANUAL query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d79cb59-2dd5-4a95-8609-ec2a2cb27c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:21:30.770 [main] WARN org.terrier.structures.BaseCompressingMetaIndex - OutOfMemoryError: Structure meta reading data file directly from disk\n",
      "Number of documents: 106400940\n",
      "Number of terms: 22580112\n",
      "Number of postings: 7942682174\n",
      "Number of fields: 1\n",
      "Number of tokens: 12168635367\n",
      "Field names: [text]\n",
      "Positions:   false\n",
      "\n",
      "CPU times: user 21.9 s, sys: 28.1 s, total: 50 s\n",
      "Wall time: 44.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "index_ref = pt.IndexRef.of(\"/data3/muntean/TREC_CAST_2022/indexes/CAST2022-stemmed/data.properties\")\n",
    "index = pt.IndexFactory.of(index_ref)\n",
    "\n",
    "print(index.getCollectionStatistics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d79622-2e64-4ba2-bbbe-f2e9f3e30900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qrel_path = \"../data/CAST_qrels/qrels-docs.2019.txt\"\n",
    "# qrels_df = pd.read_csv(qrel_path, delimiter=\" \", header=None)\n",
    "# qrels_df[[3]] = qrels_df[[3]].astype(int)\n",
    "# qrels_df = qrels_df.drop([1], axis=1)\n",
    "# qrels_df.columns=[\"qid\", \"docno\", \"label\"]\n",
    "# qrels = qrels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fdf83ac-20b4-4d15-b4e7-ccd075e1a56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics(topics_path):\n",
    "    # topics_path='./data/queries.CAST2022manual.test.tsv' #manual\n",
    "\n",
    "    topics_df = pd.read_csv(topics_path, delimiter=\"\\t\", header=None)\n",
    "\n",
    "    topics_df[2] = topics_df[1].apply(lambda s: terrier_tokenizer(s))\n",
    "\n",
    "    topics_df = topics_df.drop([1], axis=1)\n",
    "    topics_df.columns=[\"qid\", \"query\"]\n",
    "\n",
    "    topics = topics_df\n",
    "    # print(topics.head())\n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72b17331-b15b-4b04-ad81-8b72f620ea2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trec_format_to_dict_for_TRECjson(run_name, run_type, res):\n",
    "    result_dict= {}\n",
    "    # level 0\n",
    "    result_dict[\"run_name\"]=run_name\n",
    "    result_dict[\"run_type\"]=run_type\n",
    "    result_dict[\"turns\"]= []\n",
    "    \n",
    "    qids = list(res['qid'].unique())\n",
    "    \n",
    "    for turn_id in qids:\n",
    "        turn_dict = {\"turn_id\": turn_id}\n",
    "        turn_res = res[res[\"qid\"]==turn_id].reset_index()\n",
    "        responses = []\n",
    "        response = {}\n",
    "        resp = turn_res[turn_res[\"rank\"]==0][\"text\"].values[0] + \" \" + turn_res[turn_res[\"rank\"]==1][\"text\"].values[0] + \" \" + turn_res[turn_res[\"rank\"]==2][\"text\"].values[0]\n",
    "        response[\"text\"] =  \" \".join(resp.replace(\"\\\"\", \"\").split(\" \")[:250])\n",
    "        response[\"rank\"] = 1\n",
    "        response[\"provenance\"] = []\n",
    "        for i in range(0,len(turn_res)):\n",
    "            ranked_doc = {\"id\" :turn_res[\"docno\"][i], \"text\":turn_res[\"text\"][i] , \"score\":turn_res[\"score\"][i] }\n",
    "            response[\"provenance\"].append(ranked_doc)\n",
    "        responses.append(response)\n",
    "        turn_dict[\"responses\"] = responses\n",
    "        result_dict[\"turns\"].append(turn_dict)\n",
    "    \n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac07b8e6-0255-4cd4-b7f9-24415aa626fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25min 29s, sys: 1min 7s, total: 26min 37s\n",
      "Wall time: 39min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# DEPRECATED, writes TREC format\n",
    "path = \"./data/\"\n",
    "runs = [\n",
    "        #(\"queries.CAST2022.run1.prevraw.test.tsv\", \"hpc_cnr_run1\", \"automatic\"), \n",
    "         #(\"queries.CAST2022.run2.prevenriched.test.tsv\", \"hpc_cnr_run2\", \"automatic\"), \n",
    "         #(\"queries.CAST2022.run3.prevauto.test.tsv\", \"CNR_run1\", \"automatic\"), \n",
    "         # (\"queries.CAST2022.run4.prevmanual.test.tsv\", \"CNR_run2\", \"manual\"),\n",
    "         (\"queries.CAST2022.run5.rawithresponse1sent.test.tsv\", \"CNR_run3\", \"automatic\"),\n",
    "         (\"queries.CAST2022.run6.rawithresponsetop5tokens.test.tsv\", \"CNR_run4\", \"automatic\"),\n",
    "        ]\n",
    "\n",
    "for run in runs:\n",
    "    file = run[0]\n",
    "    topics = get_topics(path + file)\n",
    "    DPH = pt.BatchRetrieve(index, wmodel=\"DPH\", num_results=1000, metadata=[\"docno\",\"text\"])  \n",
    "    res = DPH.transform(topics)\n",
    "    pt.io.write_results(res,\"./runs/\"+file+\".trec\")\n",
    "    \n",
    "    result_dict = trec_format_to_dict_for_TRECjson(run[1], run[2], res)\n",
    "    with open(\"./runs/\"+file+\".json\", \"w\") as write_file:\n",
    "        json.dump(result_dict, write_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be38e44f-59e4-4d77-a683-765d6bfff181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# pt.Experiment([DPH], topics, qrels, names=[\"DPH\"], \n",
    "#               eval_metrics=[\"map\", \"recip_rank\", \"recall_200\", \"P_3\", \"P_1\", \"ndcg_cut_3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b0100b-3efa-413a-bec0-fe0d4b8ae057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# res_per_query = pt.Experiment([DPH], topics, qrels, names=[\"DPH\"], \n",
    "#               eval_metrics=[\"map\", \"recip_rank\", \"recall_200\", \"P_3\", \"P_1\", \"ndcg_cut_3\"], perquery=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08deeef-47b0-4ba3-b6f5-069ba681e2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_per_query.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2392b6ea-aafe-4149-a539-9f24a258e530",
   "metadata": {},
   "source": [
    "# RES to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a8c243-2f4d-4642-ba33-7a7a61f05fcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/res_example.tsv\", delimiter=\"\\t\")\n",
    "#df = res\n",
    "\n",
    "qids = df['qid'].unique()\n",
    "for qid in qids:\n",
    "    print(qid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e73c31-bed2-4580-9ae2-67188ac37b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952b7a10-c414-4f98-873f-6acd73bebd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = (df.groupby(['qid'])\n",
    "    .apply(lambda x: x[['summary','rank_summary']].to_dict('records'))\n",
    "    .reset_index()\n",
    "    .rename(columns={0:'responses'})\n",
    "    .to_json(orient='records')\n",
    "    )\n",
    "j = j.replace(\"\\\"summary\\\":\", \"\\\"text\\\":\").replace(\"\\\"rank_summary\\\":\", \"\\\"rank\\\":\")\n",
    "\n",
    "j2 = (df.groupby(['qid','rank_summary','summary'])\n",
    "    .apply(lambda x: x[['docno','text','score']].to_dict('records'))\n",
    "    .reset_index()\n",
    "    .rename(columns={0:'provenance'})\n",
    "    .to_json(orient='records')\n",
    "    )\n",
    "j2 = j2.replace(\"\\\"summary\\\":\", \"\\\"text\\\":\").replace(\"\\\"rank_summary\\\":\", \"\\\"rank\\\":\").replace(\"\\\"qid\\\":\", \"\\\"turn_id\\\":\").replace(\"\\\"docno\\\":\", \"\\\"id\\\":\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ab2da7-b22c-4e54-b9e8-e908b31acd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(j)\n",
    "\n",
    "import json\n",
    "with open(\"data/j.json\", \"w\") as write_file:\n",
    "    json.dump(j, write_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b0cd8b-d734-4ce8-8c9c-bb2067d5c1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(j2)\n",
    "\n",
    "import json\n",
    "with open(\"data/j2.json\", \"w\") as write_file:\n",
    "    json.dump(j2, write_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09e86b6-bc3c-4810-b567-4def58eeb3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nested example from\n",
    "#https://stackoverflow.com/questions/61781186/pandas-grouping-by-multiple-columns-to-get-a-multi-nested-json\n",
    "\n",
    "df_example = pd.read_csv(\"data/dummy_example.tsv\", delimiter=\"\\t\")\n",
    "\n",
    "print(df_example)\n",
    "\n",
    "test = [df_example.groupby(['lvl1'])\n",
    "        .apply(lambda x: x.groupby(['lvl2'])\n",
    "        .apply(lambda x: [x.groupby(['lvl3'])\n",
    "                          .apply(lambda x: x[['lvl4','lvl5']].to_dict('r')\n",
    "                        ).to_dict()]\n",
    "                         ).to_dict()\n",
    "          ).to_dict()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2458bb4b-4cdf-4328-9e7d-30772b7a1e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6497d775-9132-448f-91af-1c677d29a276",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for writing in json file\n",
    "import json\n",
    "\n",
    "with open(\"data/dummy_example.json\", \"w\") as write_file:\n",
    "    json.dump(test, write_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530f0456-87ca-4109-84ee-bd73475497a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conversational-cache",
   "language": "python",
   "name": "conversational-cache"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
