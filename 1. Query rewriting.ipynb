{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rewriting strategy, no classification is used, with memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load 3 types of utterance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "automatic_utt_file = \"./data/automatic_conv.tsv\"\n",
    "manual_utt_file = \"./data/manual_conv.tsv\"\n",
    "raw_utt_file = \"./data/raw_conv.tsv\"\n",
    "\n",
    "auto_df = pd.read_csv(automatic_utt_file, delimiter=\"\\t\", skip_blank_lines=True, header=None)\n",
    "manual_df = pd.read_csv(manual_utt_file, delimiter=\"\\t\", skip_blank_lines=True, header=None)\n",
    "raw_df = pd.read_csv(raw_utt_file, delimiter=\"\\t\", skip_blank_lines=True, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132_1-1</td>\n",
       "      <td>What was Glasgow hosting COP26 about?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132_1-3</td>\n",
       "      <td>What are the effects of COP26?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132_1-5</td>\n",
       "      <td>Can you be more specific about the future prob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132_1-7</td>\n",
       "      <td>Woah. They’re not all bad, right?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132_1-1</td>\n",
       "      <td>What was Glasgow hosting COP26 about?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>132_1-3</td>\n",
       "      <td>What are the effects of COP26?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>132_2-1</td>\n",
       "      <td>What are the future problems caused by rising ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>132_2-3</td>\n",
       "      <td>Okay, but how does COP26 affect developing cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>132_2-5</td>\n",
       "      <td>How are developed countries helping with local...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>132_2-7</td>\n",
       "      <td>Are developing countries meeting the Paris Agr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>132_2-9</td>\n",
       "      <td>Is COP26 related to last year’s conference?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>132_2-11</td>\n",
       "      <td>So what happens at each COP26 event?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>132_2-13</td>\n",
       "      <td>How are the Paris Agreement and COP22 different?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>132_1-1</td>\n",
       "      <td>What was Glasgow hosting COP26 about?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>132_1-3</td>\n",
       "      <td>What are the effects of COP26?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>132_2-1</td>\n",
       "      <td>What are the future problems caused by rising ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>132_2-3</td>\n",
       "      <td>Okay, but how does COP26 affect developing cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>132_2-5</td>\n",
       "      <td>How are developed countries helping with local...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>132_2-7</td>\n",
       "      <td>Are developing countries meeting the Paris Agr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>132_2-9</td>\n",
       "      <td>Is COP26 related to last year’s conference?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0                                                  1\n",
       "0    132_1-1              What was Glasgow hosting COP26 about?\n",
       "1    132_1-3                     What are the effects of COP26?\n",
       "2    132_1-5  Can you be more specific about the future prob...\n",
       "3    132_1-7                  Woah. They’re not all bad, right?\n",
       "4    132_1-1              What was Glasgow hosting COP26 about?\n",
       "5    132_1-3                     What are the effects of COP26?\n",
       "6    132_2-1  What are the future problems caused by rising ...\n",
       "7    132_2-3  Okay, but how does COP26 affect developing cou...\n",
       "8    132_2-5  How are developed countries helping with local...\n",
       "9    132_2-7  Are developing countries meeting the Paris Agr...\n",
       "10   132_2-9        Is COP26 related to last year’s conference?\n",
       "11  132_2-11               So what happens at each COP26 event?\n",
       "12  132_2-13   How are the Paris Agreement and COP22 different?\n",
       "13   132_1-1              What was Glasgow hosting COP26 about?\n",
       "14   132_1-3                     What are the effects of COP26?\n",
       "15   132_2-1  What are the future problems caused by rising ...\n",
       "16   132_2-3  Okay, but how does COP26 affect developing cou...\n",
       "17   132_2-5  How are developed countries helping with local...\n",
       "18   132_2-7  Are developing countries meeting the Paris Agr...\n",
       "19   132_2-9        Is COP26 related to last year’s conference?"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_dict =  dict(zip(auto_df[0],auto_df[1]))\n",
    "manual_dict =  dict(zip(manual_df[0],manual_df[1]))\n",
    "raw_dict =  dict(zip(raw_df[0],raw_df[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP utils and topic extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def create_doc(utt):\n",
    "    return nlp(utt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_person_prons = [\"he\", \"she\", \"it\", \"they\", \"him\", \"her\", \"them\", \"his\", \"her\", \"its\", \"their\"]\n",
    "\n",
    "def _rewrite_utt(doc, first_topic=\"\", previous_topic=\"\", context_list=None, trailing=False):\n",
    "        new_utt = \"\"\n",
    "        for token in doc:\n",
    "            if (token.tag_ == \"PRP\" or token.tag_ == \"PRP$\") \\\n",
    "                    and token.text in third_person_prons:\n",
    "                if previous_topic != \"\":\n",
    "                    new_utt += previous_topic + \" \"\n",
    "                if first_topic != \"\":\n",
    "                    new_utt += first_topic + \" \"\n",
    "            else:\n",
    "                new_utt += token.text + \" \"\n",
    "\n",
    "        # TRAILING THE TOPIC\n",
    "        if trailing:\n",
    "            if previous_topic.lower() not in new_utt.lower():\n",
    "                new_utt += previous_topic + \" \"\n",
    "            if first_topic.lower() not in new_utt.lower():\n",
    "                new_utt += first_topic\n",
    "\n",
    "        # TRAILING THE CONTEXT\n",
    "        if context_list is not None:\n",
    "            new_utt += \" \".join(context_list)\n",
    "\n",
    "        return new_utt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _find_cue_topic(doc):\n",
    "    cue_phrases = [\"tell me more about\", \"tell me about\", \"what about\", \"how about\"]\n",
    "    third_person_prons = [\"he\", \"she\", \"it\", \"they\", \"him\", \"her\", \"them\", \"his\", \"her\", \"its\", \"their\"]\n",
    "    \n",
    "    current_topic = \"\"\n",
    "    pron = False\n",
    "    for cue in cue_phrases:\n",
    "        if cue in str(doc).lower():\n",
    "            # check if pron:\n",
    "            for token in doc:\n",
    "                if (token.tag_ == \"PRP\" or token.tag_ == \"PRP$\") and \\\n",
    "                        token.text in third_person_prons:\n",
    "                    pron = True\n",
    "            if not pron:\n",
    "                current_topic = str(doc).lower().replace(cue, \"\").replace(\".\", \"\")\n",
    "    return current_topic\n",
    "\n",
    "\n",
    "def _find_topic(doc):\n",
    "    #pos_list = [\"nsubj\", \"dobj\", \"pobj\"]\n",
    "    topic = \"\"\n",
    "    \n",
    "    # NEW FEATURE\n",
    "    # check if it's a cue topic first\n",
    "    cue_topic = _find_cue_topic(doc)\n",
    "    if cue_topic!=\"\":\n",
    "        return cue_topic\n",
    "    \n",
    "    # GET the first topic\n",
    "    for chunk in doc.noun_chunks:\n",
    "        #if chunk.root.dep_ in pos_list:\n",
    "        if chunk.root.pos_ != \"PRON\":\n",
    "            topic += \" \" + chunk.text\n",
    "\n",
    "    # NO FIRST TOPIC - trick for \"Describe Uranus.\"\n",
    "    if topic == \"\":\n",
    "        for token in doc:\n",
    "            if token.pos_ not in [\"VERB\", \"PUNCT\"]:\n",
    "                topic += token.text + \" \"\n",
    "\n",
    "    return topic\n",
    "\n",
    "\n",
    "def _find_topic_all(doc):\n",
    "    pos_list = [\"nsubj\", \"dobj\", \"pobj\"]\n",
    "    topic = \"\"\n",
    "    \n",
    "    # NEW FEATURE\n",
    "    # check if it's a cue topic first\n",
    "    cue_topic = _find_cue_topic(doc)\n",
    "    if cue_topic!=\"\":\n",
    "        return cue_topic\n",
    "    \n",
    "    # GET the first topic\n",
    "    for chunk in doc.noun_chunks:\n",
    "        if chunk.root.pos_ != \"PRON\":\n",
    "            topic += \" \" + chunk.text\n",
    "\n",
    "    # NO FIRST TOPIC - trick for \"Describe Uranus.\"\n",
    "    if topic == \"\":\n",
    "        for token in doc:\n",
    "            if token.pos_ not in [\"VERB\", \"PUNCT\"]:\n",
    "                topic += token.text + \" \"\n",
    "\n",
    "    return topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUN 1) type: automatic (only previous): usare utterance corrente raw ed espanderla con topic della precedente raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "run1_rewritten_utt_dict = {}\n",
    "\n",
    "for i in range(0,len(raw_df)):\n",
    "    utt_id = raw_df[0][i]\n",
    "    if (utt_id.split(\"_\")[1]==\"1-1\"): # first utterace\n",
    "        first_utt = raw_df[1][i]\n",
    "        first_utt_doc =create_doc(first_utt)\n",
    "        first_topic = _find_topic(first_utt_doc)\n",
    "        run1_rewritten_utt_dict[utt_id] = first_utt\n",
    "\n",
    "    else:\n",
    "        \n",
    "        current_utt = raw_df[1][i]\n",
    "        current_utt_doc = create_doc(current_utt)\n",
    "        \n",
    "        # get the previous topic\n",
    "        prev_utt_id = raw_df[0][i-1]\n",
    "        prev_utt_doc = create_doc(raw_dict[prev_utt_id]) \n",
    "        prev_topic = _find_topic(prev_utt_doc)\n",
    "        new_utt = _rewrite_utt(current_utt_doc, first_topic = \"\", previous_topic=prev_topic, context_list=None, trailing=True)\n",
    "        run1_rewritten_utt_dict[utt_id] = new_utt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k,v in run1_rewritten_utt_dict.items():\n",
    "#     print(k, raw_dict[k],\"====>\",  v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write results\n",
    "with open(\"./data/queries.CAST2022.run1.prevraw.test.tsv\", \"w\") as f:\n",
    "    for k,v in run1_rewritten_utt_dict.items():\n",
    "        f.write(\"{}\\t{}\\n\".format(k,v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) type: automatic (previous with history): usare utterance corrente raw ed espanderla con topic della precedente raw già arricchita (dovrebbe propagare i topic)\n",
    "\n",
    "label is not used, always propagate *with memory: topics are extracted from previous enriched utterance*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "run2_rewritten_utt_dict = {}\n",
    "\n",
    "for i in range(0,len(raw_df)):\n",
    "    utt_id = raw_df[0][i]\n",
    "    if (utt_id.split(\"_\")[1]==\"1-1\"): # first utterace\n",
    "        first_utt = raw_df[1][i]\n",
    "        first_utt_doc =create_doc(first_utt)\n",
    "        first_topic = _find_topic(first_utt_doc)\n",
    "        run2_rewritten_utt_dict[utt_id] = first_utt\n",
    "\n",
    "    else:\n",
    "        \n",
    "        current_utt = raw_df[1][i]\n",
    "        current_utt_doc = create_doc(current_utt)\n",
    "        \n",
    "        # get the previous topic\n",
    "        prev_utt_id = raw_df[0][i-1]\n",
    "        prev_utt_doc = create_doc(run2_rewritten_utt_dict[prev_utt_id]) \n",
    "        prev_topic = _find_topic(prev_utt_doc)\n",
    "        new_utt = _rewrite_utt(current_utt_doc, first_topic = \"\", previous_topic=prev_topic, context_list=None, trailing=True)\n",
    "        run2_rewritten_utt_dict[utt_id] = new_utt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k,v in run2_rewritten_utt_dict.items():\n",
    "#     print(k, raw_dict[k],\"====>\",  v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write results\n",
    "with open(\"./data/queries.CAST2022.run2.prevenriched.test.tsv\", \"w\") as f:\n",
    "    for k,v in run2_rewritten_utt_dict.items():\n",
    "        f.write(\"{}\\t{}\\n\".format(k,v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) type: automatic (previous with provided auto):  usare utterance corrente raw ed espanderla con topic della precedente automatically rewritten by CAsT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "run3_rewritten_utt_dict = {}\n",
    "\n",
    "for i in range(0,len(raw_df)):\n",
    "    utt_id = raw_df[0][i]\n",
    "    if (utt_id.split(\"_\")[1]==\"1-1\"): # first utterace\n",
    "        first_utt = raw_df[1][i]\n",
    "        first_utt_doc =create_doc(first_utt)\n",
    "        first_topic = _find_topic(first_utt_doc)\n",
    "        run3_rewritten_utt_dict[utt_id] = first_utt\n",
    "\n",
    "    else:\n",
    "        \n",
    "        current_utt = raw_df[1][i]\n",
    "        current_utt_doc = create_doc(current_utt)\n",
    "        \n",
    "        # get the previous topic\n",
    "        prev_utt_id = raw_df[0][i-1]\n",
    "        prev_utt_doc = create_doc(auto_dict[prev_utt_id]) \n",
    "        prev_topic = _find_topic(prev_utt_doc)\n",
    "        new_utt = _rewrite_utt(current_utt_doc, first_topic = \"\", previous_topic=prev_topic, context_list=None, trailing=True)\n",
    "        run3_rewritten_utt_dict[utt_id] = new_utt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k,v in run3_rewritten_utt_dict.items():\n",
    "#     print(k, raw_dict[k],\"====>\",auto_dict[k],\"====>\",  v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write results\n",
    "with open(\"./data/queries.CAST2022.run3.prevauto.test.tsv\", \"w\") as f:\n",
    "    for k,v in run3_rewritten_utt_dict.items():\n",
    "        f.write(\"{}\\t{}\\n\".format(k,v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) type: manual  (previous with provided manual):  usare utterance corrente raw ed espanderla con topic della precedente manually rewritten by CAsT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "run4_rewritten_utt_dict = {}\n",
    "\n",
    "for i in range(0,len(raw_df)):\n",
    "    utt_id = raw_df[0][i]\n",
    "    if (utt_id.split(\"_\")[1]==\"1-1\"): # first utterace\n",
    "        first_utt = raw_df[1][i]\n",
    "        first_utt_doc =create_doc(first_utt)\n",
    "        first_topic = _find_topic(first_utt_doc)\n",
    "        run4_rewritten_utt_dict[utt_id] = first_utt\n",
    "\n",
    "    else:\n",
    "        \n",
    "        current_utt = raw_df[1][i]\n",
    "        current_utt_doc = create_doc(current_utt)\n",
    "        \n",
    "        # get the previous topic\n",
    "        prev_utt_id = raw_df[0][i-1]\n",
    "        prev_utt_doc = create_doc(manual_dict[prev_utt_id]) \n",
    "        prev_topic = _find_topic(prev_utt_doc)\n",
    "        new_utt = _rewrite_utt(current_utt_doc, first_topic = \"\", previous_topic=prev_topic, context_list=None, trailing=True)\n",
    "        run4_rewritten_utt_dict[utt_id] = new_utt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k,v in run4_rewritten_utt_dict.items():\n",
    "#     print(k, raw_dict[k],\"====>\", manual_dict[k],\"====>\",  v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write results\n",
    "with open(\"./data/queries.CAST2022.run4.prevmanual.test.tsv\", \"w\") as f:\n",
    "    for k,v in run4_rewritten_utt_dict.items():\n",
    "        f.write(\"{}\\t{}\\n\".format(k,v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) raw with prev response, nounchuncks from first sentence\n",
    "alternatively from entire passage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>turn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132</td>\n",
       "      <td>[{'number': '1-1', 'utterance': 'I remember Gl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132</td>\n",
       "      <td>[{'number': '1-1', 'utterance': 'I remember Gl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>132</td>\n",
       "      <td>[{'number': '1-1', 'utterance': 'I remember Gl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>133</td>\n",
       "      <td>[{'number': '1-1', 'utterance': 'I’d like to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>133</td>\n",
       "      <td>[{'number': '1-1', 'utterance': 'I’d like to a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number                                               turn\n",
       "0     132  [{'number': '1-1', 'utterance': 'I remember Gl...\n",
       "1     132  [{'number': '1-1', 'utterance': 'I remember Gl...\n",
       "2     132  [{'number': '1-1', 'utterance': 'I remember Gl...\n",
       "3     133  [{'number': '1-1', 'utterance': 'I’d like to a...\n",
       "4     133  [{'number': '1-1', 'utterance': 'I’d like to a..."
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_path = \"/data3/muntean/TREC_CAST_2022/data/2022_evaluation_topics_flattened_duplicated_v1.0.json\"\n",
    "topics_df = pd.read_json(topics_path)\n",
    "topics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_dict = {}\n",
    "for i in range(len(topics_df)):\n",
    "    conv_number = topics_df[\"number\"][i]\n",
    "    conv_tree_list = topics_df[\"turn\"][i]\n",
    "    for turn in conv_tree_list:\n",
    "        turn_id = str(conv_number) + \"_\" + str(turn[\"number\"])\n",
    "        if \"response\" in turn: \n",
    "            response_dict[turn_id] = turn[\"response\"]\n",
    "# response_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "run5_rewritten_utt_dict = {}\n",
    "\n",
    "for i in range(0,len(raw_df)):\n",
    "    utt_id = raw_df[0][i]\n",
    "    if (utt_id.split(\"_\")[1]==\"1-1\"): # first utterace\n",
    "        # print()\n",
    "        first_utt_response = response_dict[utt_id].split(\".\")[0]\n",
    "        # print(first_utt_response)\n",
    "        first_utt_response_doc = create_doc(first_utt_response)\n",
    "        first_response_topic = _find_topic(first_utt_response_doc)\n",
    "        # print(\"FT: \", utt_id, raw_df[1][i], first_response_topic)\n",
    "        run5_rewritten_utt_dict[utt_id] = raw_df[1][i]\n",
    "        # print()\n",
    "\n",
    "    else:\n",
    "        \n",
    "        current_utt = raw_df[1][i]\n",
    "        # current_utt_doc = create_doc(current_utt)\n",
    "        \n",
    "        # get the previous topic\n",
    "        prev_utt_id = raw_df[0][i-1]\n",
    "        prev_utt_response_doc = create_doc(response_dict[prev_utt_id].split(\".\")[0]) \n",
    "        prev_response_topic = _find_topic(prev_utt_response_doc)\n",
    "        # print(raw_df[0][i], raw_df[1][i], prev_response_topic)\n",
    "        # new_utt = current_utt + \" \" + first_response_topic + \" \" + prev_response_topic\n",
    "        new_utt = current_utt + \" \" + prev_response_topic\n",
    "        run5_rewritten_utt_dict[utt_id] = new_utt\n",
    "        # print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run5_rewritten_utt_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write results\n",
    "with open(\"./data/queries.CAST2022.run5.rawithresponse1sent.test.tsv\", \"w\") as f:\n",
    "    for k,v in run5_rewritten_utt_dict.items():\n",
    "        f.write(\"{}\\t{}\\n\".format(k,v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) raw with prev response, top 5 frequent tokens after stopword removal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def top5_nouns(response):\n",
    "    docx = nlp(response.lower())\n",
    "\n",
    "    # Just looking at nouns\n",
    "    nouns = []\n",
    "    for token in docx:\n",
    "        if token.is_stop != True and token.is_punct != True and token.pos_ == 'NOUN':\n",
    "            nouns.append(str(token))\n",
    "    top5 = Counter(nouns).most_common(5)\n",
    "    # print(top10)\n",
    "    return \" \".join([str(x) for x,y in top5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "run6_rewritten_utt_dict = {}\n",
    "\n",
    "for i in range(0,len(raw_df)):\n",
    "    utt_id = raw_df[0][i]\n",
    "    if (utt_id.split(\"_\")[1]==\"1-1\"): # first utterace\n",
    "        # print()\n",
    "        first_utt_response = response_dict[utt_id]\n",
    "        # print(first_utt_response)\n",
    "        # first_utt_response_doc = create_doc(first_utt_response)\n",
    "        # first_response_topic = _find_topic_all(first_utt_response_doc)\n",
    "        first_response_top5_topic = top5_nouns(first_utt_response)\n",
    "        # print(\"FT: \", utt_id, raw_df[1][i], first_response_topic)\n",
    "        run6_rewritten_utt_dict[utt_id] = raw_df[1][i]\n",
    "        # print()\n",
    "\n",
    "    else:\n",
    "        \n",
    "        current_utt = raw_df[1][i]\n",
    "        # current_utt_doc = create_doc(current_utt)\n",
    "        \n",
    "        # get the previous topic\n",
    "        prev_utt_id = raw_df[0][i-1]\n",
    "        # prev_utt_response_doc = create_doc(response_dict[prev_utt_id]) \n",
    "        # prev_response_topic = _find_topic_all(prev_utt_response_doc)\n",
    "        prev_response_top5_topic = top5_nouns(response_dict[prev_utt_id])\n",
    "        # print(raw_df[0][i], raw_df[1][i], prev_response_topic)\n",
    "        # new_utt = current_utt + \" \" + first_response_topic + \" \" + prev_response_topic\n",
    "        new_utt = current_utt + \" \" + prev_response_top5_topic\n",
    "        run6_rewritten_utt_dict[utt_id] = new_utt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run6_rewritten_utt_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write results\n",
    "with open(\"./data/queries.CAST2022.run6.rawithresponsetop5tokens.test.tsv\", \"w\") as f:\n",
    "    for k,v in run6_rewritten_utt_dict.items():\n",
    "        f.write(\"{}\\t{}\\n\".format(k,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
